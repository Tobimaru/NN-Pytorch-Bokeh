{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D GAN distribution sampling\n",
    "\n",
    "This notebook contains a PyTorch implementation of the GAN example as presented at   \n",
    "http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/\n",
    "\n",
    "It's a relatively simple problem in which the generator tries to mimic a Gaussian distribution.\n",
    "The generator is fed by sampling a noise distribution while the discriminator tries to distinguish between samples drawn from the Gaussian distribution and samples as generated by the generator from the noise samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, ConcatDataset, DataLoader\n",
    "\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import output_notebook, figure, show\n",
    "from bokeh.layouts import row\n",
    "from bokeh.io import push_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"03a479f4-634b-4fc3-b070-4cfb18aceb69\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(`.${CLASS_NAME.split(' ')[0]}`);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"03a479f4-634b-4fc3-b070-4cfb18aceb69\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"03a479f4-634b-4fc3-b070-4cfb18aceb69\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '03a479f4-634b-4fc3-b070-4cfb18aceb69' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"03a479f4-634b-4fc3-b070-4cfb18aceb69\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"03a479f4-634b-4fc3-b070-4cfb18aceb69\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"03a479f4-634b-4fc3-b070-4cfb18aceb69\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '03a479f4-634b-4fc3-b070-4cfb18aceb69' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"03a479f4-634b-4fc3-b070-4cfb18aceb69\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#embed figures in the notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_real(n, sigma=1.0, mean=-1.0):\n",
    "    return np.sort(np.random.normal(mean, sigma, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_noise(n, bound=5.0):\n",
    "    #use stratified sampling to ensure the mapping maintains ordering \n",
    "    # (see blog for details)\n",
    "    return np.linspace(-bound, bound, n) + \\\n",
    "            np.random.random(n) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sampler(object):\n",
    "    def __init__(self, real_sigma, real_mean, \n",
    "                 noise_range, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        #initialize data providers\n",
    "        self.real_data = RealData(self.batch_size, \n",
    "                                  real_sigma, real_mean)\n",
    "        self.fake_data = FakeData(self.batch_size, noise_range)\n",
    "        self.real_inputs = DataLoader(\n",
    "            self.real_data, batch_size=self.batch_size, \n",
    "            shuffle=False, num_workers=1)\n",
    "        self.fake_inputs = DataLoader(\n",
    "            self.fake_data, batch_size=self.batch_size, \n",
    "            shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap sampling in PyTorch Datasets\n",
    "\n",
    "to use PyTorch sampling functionalities when training the networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RealData(Dataset):\n",
    "    def __init__(self, n, sigma, mean):\n",
    "        self.data_size = n\n",
    "        self.sigma = sigma\n",
    "        self.mean = mean\n",
    "    \n",
    "    def sample(self):\n",
    "        self.x = torch.FloatTensor(sample_real(\n",
    "            self.data_size, self.sigma, self.mean)).unsqueeze(-1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FakeData(Dataset):\n",
    "    def __init__(self, n, bound):\n",
    "        self.data_size = n\n",
    "        self.bound = bound\n",
    "        \n",
    "    def sample(self):\n",
    "        self.x = torch.FloatTensor(sample_noise(\n",
    "            self.data_size, self.bound)).unsqueeze(-1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        # first linear fully connected layer\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        # apply nonlinear activation using softplus\n",
    "        self.softplus = nn.Softplus()\n",
    "        # reduce to single output using fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        nn.init.normal(self.fc1.weight.data)\n",
    "        nn.init.constant(self.fc1.bias.data, 0.0)\n",
    "        nn.init.normal(self.fc2.weight.data)\n",
    "        nn.init.constant(self.fc2.bias.data, 0.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc2(self.softplus(self.fc1(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.fc_layers = nn.ModuleList(\n",
    "            [nn.Linear(input_dim, hidden_dim)] + \n",
    "            [nn.Linear(hidden_dim, hidden_dim) for i in range(2)] +\n",
    "            [nn.Linear(hidden_dim, 1)])\n",
    "        \n",
    "        self.activations = nn.ModuleList(\n",
    "            [nn.ReLU() for i in range(3)] + [nn.Sigmoid()])\n",
    "        \n",
    "        for layer in self.fc_layers:\n",
    "            nn.init.normal(layer.weight.data)\n",
    "            nn.init.constant(layer.bias.data, 0.0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for fc, activ in zip(self.fc_layers, self.activations):\n",
    "            x = activ(fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the GAN\n",
    "\n",
    "This combines sampler, generator and discriminator, and defines the loss function and optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(nn.Module):\n",
    "    def __init__(self, sampler, generator, discriminator):\n",
    "        super(GAN, self).__init__()\n",
    "        \n",
    "        self.sampler = sampler\n",
    "        \n",
    "        # initialize labels used for training\n",
    "        self.real_labels = torch.ones(self.sampler.batch_size,1)\n",
    "        self.fake_labels = torch.zeros(self.sampler.batch_size,1)\n",
    "        \n",
    "        # construct models\n",
    "        self.generator = generator\n",
    "        # to make sure the discriminator does not get overwhelmed,\n",
    "        # we give it two times more hidden neurons \n",
    "        self.discriminator = discriminator      \n",
    "        self.criterion = nn.BCELoss() # binary cross entropy loss\n",
    "        self.optim_gen = optim.Adam(\n",
    "            self.generator.parameters(), lr=0.001)\n",
    "        self.optim_discrim = optim.Adam(\n",
    "            self.discriminator.parameters(), lr=0.001)\n",
    "        \n",
    "        # for logging\n",
    "        self.discrim_loss = {'real': None, 'fake': None}\n",
    "        self.gen_loss = None\n",
    "    \n",
    "    def learn(self):\n",
    "        # GAN learning without resampling for the generator step\n",
    "        \n",
    "        self.sampler.real_data.sample()\n",
    "        self.sampler.fake_data.sample()\n",
    "        \n",
    "        # iterate over minibatches (in this case only one)\n",
    "        for real_x, fake_x in \\\n",
    "            zip(self.sampler.real_inputs, self.sampler.fake_inputs):\n",
    "            \n",
    "            self.discrim_loss['real'], self.discrim_loss['fake'] = \\\n",
    "                self._step_discriminator(real_x, fake_x)\n",
    "            self.gen_loss = self._step_generator(fake_x)\n",
    "                             \n",
    "    def learn_discriminator(self):\n",
    "        \n",
    "        self.sampler.real_data.sample()\n",
    "        self.sampler.fake_data.sample()\n",
    "        \n",
    "        for real_x, fake_x in \\\n",
    "            zip(self.sampler.real_inputs, self.sampler.fake_inputs):\n",
    "        \n",
    "            self.discrim_loss['real'], self.discrim_loss['fake'] = \\\n",
    "                    self._step_discriminator(real_x, fake_x)\n",
    "            \n",
    "    def learn_generator(self):\n",
    "        \n",
    "        self.sampler.fake_data.sample()\n",
    "        \n",
    "        for x in self.sampler.fake_inputs:\n",
    "            self.gen_loss = self._step_generator(x)\n",
    "            \n",
    "    def _step_discriminator(self, real_x, fake_x):\n",
    "        \n",
    "        # Learn discriminator (keep generator fixed).\n",
    "        # We want to compute the loss = \n",
    "        # -log(discrim(real_x)) - log(1 - discrim(gen(fake_x)).\n",
    "        # To do so, both terms can be computed separately,\n",
    "        # because the gradients are added together\n",
    "        # when calling backward()\n",
    "        \n",
    "        self.discriminator.zero_grad()\n",
    "        output = self.discriminator(Variable(real_x))\n",
    "        loss_real = self.criterion(output, Variable(self.real_labels))\n",
    "        loss_real.backward()\n",
    "\n",
    "        forged = self.generator(Variable(fake_x))\n",
    "        # call detach because we don't need to update\n",
    "        # the gradients for the generator (parameters are \n",
    "        # not trained in this step)\n",
    "        output = self.discriminator(forged.detach())\n",
    "        loss_fake = self.criterion(output, Variable(self.fake_labels))\n",
    "        loss_fake.backward()\n",
    "        \n",
    "        self.optim_discrim.step()\n",
    "        \n",
    "        return loss_real.data[0], loss_fake.data[0]\n",
    "    \n",
    "    def _step_generator(self, x):\n",
    "    \n",
    "        # Learn generator (keep discriminator fixed).\n",
    "        \n",
    "        self.generator.zero_grad()\n",
    "        output = self.discriminator(self.generator(Variable(x)))\n",
    "        # TODO: Not sure here if gradients are computed for the discriminator,\n",
    "        # and if so, how to prevent that. \n",
    "        loss = self.criterion(output, Variable(self.real_labels))\n",
    "        loss.backward()\n",
    "        self.optim_gen.step()\n",
    "        \n",
    "        return loss.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging and plotting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging of losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_discriminator(loss_real, loss_fake):\n",
    "    print('discriminator | '\n",
    "          '{:.4f} | {:.4f} | {:.4f}'.format(\n",
    "              loss_real, loss_fake, loss_real + loss_fake)) \n",
    "    \n",
    "def log_generator(loss):\n",
    "    print('generator | {:.4f}'.format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot the decision boundary, the real Gaussian distribution, and the forged distribution as generated by the generator in a figure. The evolution of the losses will be plotted in a second figure. The following functions construct data structures to store the data needed to update the figures in bokeh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_real_hist(numb_points, numb_bins, sampler):\n",
    "    \n",
    "    mean = sampler.real_data.mean\n",
    "    sigma = sampler.real_data.sigma\n",
    "    sample_range = gan.sampler.fake_data.bound\n",
    "    \n",
    "    dat = {}\n",
    "    \n",
    "    samples_real = sample_real(numb_points, sigma, mean)\n",
    "    \n",
    "    hist_bins = np.linspace(-sample_range, sample_range, numb_bins)\n",
    "    dat['hist_real'], _ = np.histogram(samples_real, \n",
    "                                       bins=hist_bins, density=True) \n",
    "    dat['x'] = np.linspace(-sample_range, sample_range, numb_bins - 1)\n",
    "    \n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_gan_hist(numb_points, numb_bins, gan):\n",
    "    \n",
    "    sample_range = gan.sampler.fake_data.bound\n",
    "    \n",
    "    dat = {}\n",
    "    \n",
    "    # fake distribution\n",
    "    gen_x = torch.FloatTensor(np.linspace(\n",
    "        -sample_range, sample_range, numb_points)).unsqueeze(-1)\n",
    "    samples_fake = gan.generator(Variable(gen_x)).data.numpy().squeeze(-1)\n",
    "    hist_bins = np.linspace(-sample_range, sample_range, numb_bins)\n",
    "    dat['hist_fake'], _ = np.histogram(samples_fake, \n",
    "                                       bins=hist_bins, density=True)\n",
    "    \n",
    "    # decision boundary (numb_bins - 1 to get same length as \n",
    "    # fake distribution data, otherwise bokeh is complaining\n",
    "    xs = np.linspace(-sample_range, sample_range, numb_bins - 1)\n",
    "    discr_x = torch.FloatTensor(xs).unsqueeze(-1)\n",
    "    dat['labels'] = gan.discriminator(\n",
    "        Variable(discr_x)).data.numpy().squeeze(-1) \n",
    "    \n",
    "    dat['x'] = xs\n",
    "    \n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_data_gan_loss(gan, old_dat, epoch):\n",
    "    \n",
    "    dat = {}\n",
    "    dat['x'] = np.append(old_dat['x'], [epoch]) \\\n",
    "               if epoch else np.array([epoch])\n",
    "    dloss_real = gan.discrim_loss['real']\n",
    "    dloss_fake = gan.discrim_loss['fake']\n",
    "    dat['loss_discrim_real'] = np.append(old_dat['loss_discrim_real'], \n",
    "                                  [dloss_real]) \\\n",
    "                               if epoch else np.array([dloss_real])\n",
    "    dat['loss_discrim_fake'] = np.append(old_dat['loss_discrim_fake'], \n",
    "                                  [dloss_fake]) \\\n",
    "                               if epoch else np.array([dloss_fake])\n",
    "    dat['loss_discrim_total'] = np.append(old_dat['loss_discrim_total'], \n",
    "                                  [dloss_real + dloss_fake]) \\\n",
    "                                if epoch else np.array([dloss_real + dloss_fake])\n",
    "    dat['loss_generator'] = np.append(old_dat['loss_generator'], \n",
    "                                      [gan.gen_loss]) \\\n",
    "                            if epoch else np.array([gan.gen_loss])\n",
    "    \n",
    "    return dat\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function displays the figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_data(data_real_hist, data_gan_hist, data_gan_loss, bound):\n",
    "    \n",
    "    lw = 2\n",
    "    \n",
    "    fig_hist = figure(plot_width=350, plot_height=350,\n",
    "                      x_range=(-bound, bound))\n",
    "\n",
    "    fig_hist.line('x', 'hist_real', source=data_real_hist,\n",
    "             line_width=lw, line_color='blue', legend='real distribution')\n",
    "    fig_hist.line('x', 'labels', source=data_gan_hist,\n",
    "             line_width=lw, line_color='green', legend='decision')\n",
    "    fig_hist.line('x', 'hist_fake', source=data_gan_hist, \n",
    "             line_width=lw, line_color='red', legend='fake distribution')\n",
    "    \n",
    "    # unfortunately legends cannot be moved (yet) interactively\n",
    "    fig_hist.legend.location = \"top_left\"\n",
    "    #fig.legend.click_policy=\"hide\"\n",
    "    \n",
    "    fig_loss = figure(plot_width=640, plot_height=350)\n",
    "    fig_loss.line('x', 'loss_discrim_real', source=data_gan_loss, \n",
    "                  line_width=lw, line_color='blue', legend='D-loss real')\n",
    "    fig_loss.line('x', 'loss_discrim_fake', source=data_gan_loss, \n",
    "                  line_width=lw, line_color='green', legend='D-loss fake')\n",
    "    fig_loss.line('x', 'loss_discrim_total', source=data_gan_loss, \n",
    "                  line_width=lw, line_color='red', legend='D-loss total')\n",
    "    fig_loss.line('x', 'loss_generator', source=data_gan_loss, \n",
    "                  line_width=lw, line_color='black', legend='G-loss')\n",
    "    \n",
    "    show(row(fig_hist, fig_loss), notebook_handle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the GAN\n",
    "\n",
    "Note that this problem is not stable and can generate various solution, depending on the random seed or on how many times you run the cells. As explained in the blog, the generator will typically converge to a distribution that has similar range but has a more narrow shape. To improve convergence, a pre-training of the decision boundary can be applied as explained in https://blog.evjang.com/2016/06/generative-adversarial-nets-in.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_sigma = 0.5\n",
    "real_mean = 4.0\n",
    "noise_range = 8.0\n",
    "hidden_dim = 4\n",
    "batch_size = 8\n",
    "sampler = Sampler(real_sigma, real_mean, noise_range, batch_size)\n",
    "gen = Generator(1, hidden_dim)\n",
    "discrim = Discriminator(1, 2 * hidden_dim)\n",
    "gan = GAN(sampler, gen, discrim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_points = 4000\n",
    "nb_bins = 100\n",
    "\n",
    "log_step = 10\n",
    "number_epochs = 5000\n",
    "\n",
    "data_real = ColumnDataSource(\n",
    "    data=get_data_real_hist(nb_points, nb_bins, sampler))\n",
    "data_gan_hist = ColumnDataSource(\n",
    "    data={'x': [], 'labels': [], 'hist_fake': []})\n",
    "# when using empty arrays, y-axis tick labels are not showing\n",
    "data_gan_loss = ColumnDataSource(\n",
    "    data={'x': [0.], \n",
    "          'loss_discrim_real': [0.],\n",
    "          'loss_discrim_fake': [0.],\n",
    "          'loss_discrim_total': [0.],\n",
    "          'loss_generator': [0.]})\n",
    "\n",
    "show_data(data_real, data_gan_hist, data_gan_loss, \n",
    "          gan.sampler.fake_data.bound)\n",
    "\n",
    "for epoch in range(number_epochs):\n",
    "    #gan.learn()\n",
    "    gan.learn_discriminator()\n",
    "    gan.learn_generator()\n",
    "    \n",
    "    if not (epoch % log_step):\n",
    "        data_gan_hist.data = get_data_gan_hist(4000, 100, gan)\n",
    "        data_gan_loss.data = update_data_gan_loss(\n",
    "            gan, data_gan_loss.data, epoch)\n",
    "        push_notebook()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test generator\n",
    "\n",
    "This performs a test to validate the behavior of the generator. It's tested against an implementation of the same model using numpy. It illustrates how weights and bias values in PyTorch layers can be set to evaluate a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_numpy():\n",
    "    in_vals = np.matrix([[1. , 2., 3., 4.]])\n",
    "    w1 = np.matrix([[1.], [2.], [3.], [4.]])\n",
    "    w2 = np.matrix([[1., 2., 3., 4.]])\n",
    "    res1 = w1 * in_vals\n",
    "    res2 = np.log(1. + np.exp(res1))\n",
    "    res3 = w2 * res2\n",
    "    return res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_dims_test = 4\n",
    "test_weights = np.array([[1.], [2.], [3.], [4.]])\n",
    "weights_gen_fc1 = test_weights\n",
    "bias_gen_fc1 = np.zeros((hidden_dims_test,1))\n",
    "weights_gen_fc2 = test_weights.transpose()\n",
    "bias_gen_fc2 = np.zeros((1,1))\n",
    "\n",
    "gen = Generator(1,hidden_dims_test)\n",
    "gen.fc1.weight.data = torch.FloatTensor(weights_gen_fc1)\n",
    "gen.fc1.bias.data = torch.FloatTensor(bias_gen_fc1)\n",
    "gen.fc2.weight.data = torch.FloatTensor(weights_gen_fc2)\n",
    "gen.fc2.bias.data = torch.FloatTensor(bias_gen_fc2)\n",
    "\n",
    "res = gen(Variable(torch.FloatTensor([[1.], [2.], [3.], [4.]])))\n",
    "\n",
    "np.testing.assert_almost_equal(\n",
    "    res.data.numpy(),                            \n",
    "    generator_numpy().transpose(), decimal=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test discriminator\n",
    "\n",
    "This performs a test of the discriminator model, using baseline values obtained by running equivalent model in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_dims_test = 4\n",
    "test_weights = np.array([[0.5, -1.5, 0.33, -0.15]])\n",
    "weights = [test_weights.transpose(), \n",
    "           np.tile(test_weights, (4,1)),\n",
    "           np.tile(test_weights, (4,1)).transpose(), \n",
    "           np.array(np.fliplr(test_weights))] \n",
    "# pytorch does not (yet) support negative stride\n",
    "\n",
    "discrim = Discriminator(1, hidden_dims_test)    \n",
    "for layer, w in zip(discrim.fc_layers, weights):\n",
    "    layer.weight.data = torch.FloatTensor(w)\n",
    "\n",
    "res = discrim(Variable(torch.FloatTensor(\n",
    "    [[1.0],[0.5],[3.0],[0.0]])))\n",
    "\n",
    "np.testing.assert_almost_equal(\n",
    "    res.data.numpy(),\n",
    "    [[0.3061263], [0.3991169], [0.0790827], [0.5]],\n",
    "    decimal=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
